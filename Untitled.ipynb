{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895f8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Считываю данные\n",
    "# pd.set_option('display.max_columns', None)\n",
    "X = pd.read_csv(\"train.tsv.gz\", sep=\"\\t\")\n",
    "Xtest = pd.read_csv(\"test.tsv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398e0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняю пустые столбцы с текстом пустыми строками\n",
    "X['raw_branded_description'] = X['raw_branded_description'].fillna(\"\")\n",
    "X['lemmaized_wo_stopwords_raw_branded_description'] = X['lemmaized_wo_stopwords_raw_branded_description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de44d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest['raw_branded_description'] = Xtest['raw_branded_description'].fillna(\"\")\n",
    "Xtest['lemmaized_wo_stopwords_raw_branded_description'] = Xtest['lemmaized_wo_stopwords_raw_branded_description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7dc4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняю пустые столбцы с краткой информацией пустыми строками\n",
    "X['employer_id'] = X['employer_id'].fillna(-1)\n",
    "X['unified_address_region'] = X['unified_address_region'].fillna('NoneInformation')\n",
    "X['unified_address_city'] = X['unified_address_city'].fillna('NoneInformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c1d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest['employer_id'] = Xtest['employer_id'].fillna(-1)\n",
    "Xtest['unified_address_region'] = Xtest['unified_address_region'].fillna('NoneInformation')\n",
    "Xtest['unified_address_city'] = Xtest['unified_address_city'].fillna('NoneInformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b623408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bool как int\n",
    "X['accept_handicapped'] = X['accept_handicapped'].astype(int)\n",
    "X['accept_kids'] = X['accept_kids'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3602e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest['accept_handicapped'] = Xtest['accept_handicapped'].astype(int)\n",
    "Xtest['accept_kids'] = Xtest['accept_kids'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0693d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float как int\n",
    "X['employer_id'] = X['employer_id'].astype(int)\n",
    "Xtest['employer_id'] = Xtest['employer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aad3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена (там где могу)\n",
    "X[\"key_skills_name\"] = X[\"key_skills_name\"].apply(lambda x: \"\" if x == \"не указано\" else x)\n",
    "Xtest[\"key_skills_name\"] = Xtest[\"key_skills_name\"].apply(lambda x: \"\" if x == \"не указано\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81857ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"if_foreign_language\"] = X[\"if_foreign_language\"].apply(lambda x: 1 if x == \"Указано\" else 0)\n",
    "X[\"is_branded_description\"] = X[\"is_branded_description\"].apply(lambda x: 1 if x == \"заполнено\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba0ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest[\"if_foreign_language\"] = Xtest[\"if_foreign_language\"].apply(lambda x: 1 if x == \"Указано\" else 0)\n",
    "Xtest[\"is_branded_description\"] = Xtest[\"is_branded_description\"].apply(lambda x: 1 if x == \"заполнено\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dd8dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляю лишнее\n",
    "to_drop = ['name',\n",
    "           'unified_address_country',\n",
    "           'raw_description',\n",
    "           'raw_branded_description']\n",
    "X = X.drop(to_drop, axis=1)\n",
    "Xtest = Xtest.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1fe362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# le = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# for i in ['experience_name', 'schedule_name', 'unified_address_city', 'unified_address_state', 'unified_address_region',\n",
    "#           'specializations_profarea_name', 'employment_name', 'employer_industries']:\n",
    "#     X[i] = le.fit_transform(X[i].to_frame())\n",
    "#     Xtest[i] = le.transform(Xtest[i].to_frame())\n",
    "# X\n",
    "# категориальные признаки\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "enc = DictVectorizer()\n",
    "X_train_categ = enc.fit_transform(X[['experience_name', 'schedule_name', 'unified_address_city', 'unified_address_state', 'unified_address_region',\n",
    "           'specializations_profarea_name', 'employment_name', 'employer_industries']].to_dict('records'))#.toarray()\n",
    "X_test_categ = enc.transform(Xtest[['experience_name', 'schedule_name', 'unified_address_city', 'unified_address_state', 'unified_address_region',\n",
    "           'specializations_profarea_name', 'employment_name', 'employer_industries']].to_dict('records'))#.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8a078d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\peret\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# библиотеки\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import pymorphy2\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=4, max_df=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bd293f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# обработка текста\n",
    "for i in ['employer_name', 'key_skills_name', 'professional_roles_name', 'languages_name',\n",
    "          'lemmaized_wo_stopwords_raw_description', 'lemmaized_wo_stopwords_raw_branded_description', 'name_clean']:\n",
    "#     нижний регистр\n",
    "    X[i] = X[i].apply(lambda x: x.lower())\n",
    "#     только буквы, пробел и тире\n",
    "    X[i] = X[i].apply(lambda x: re.sub(r'[^A-Za-zА-Яа-яЁё -]', '', x))\n",
    "\n",
    "    Xtest[i] = Xtest[i].apply(lambda x: x.lower())\n",
    "    Xtest[i] = Xtest[i].apply(lambda x: re.sub(r'[^A-Za-zА-Яа-яЁё -]', '', x))\n",
    "\n",
    "    if i in ['employer_name', 'key_skills_name', 'professional_roles_name', 'languages_name']:\n",
    "#         удаляю частые слова\n",
    "        X[i] = X[i].apply(lambda x: \" \".join([j for j in word_tokenize(x) if j not in russian_stopwords]))\n",
    "#     лемматизация\n",
    "        X[i] = X[i].apply(lambda x: \" \".join([morph.parse(j)[0].normal_form for j in word_tokenize(x)]))\n",
    "\n",
    "        Xtest[i] = Xtest[i].apply(lambda x: \" \".join([j for j in word_tokenize(x) if j not in russian_stopwords]))\n",
    "        Xtest[i] = Xtest[i].apply(lambda x: \" \".join([morph.parse(j)[0].normal_form for j in word_tokenize(x)]))\n",
    "# обработка текста\n",
    "train_text = vectorizer.fit_transform(X['employer_name'] + ' ' + X['key_skills_name'] + ' ' + X['professional_roles_name'] + ' ' + X['languages_name'] + ' ' + X['lemmaized_wo_stopwords_raw_description'] + ' ' + X['lemmaized_wo_stopwords_raw_branded_description'] + \" \" + X['name_clean'])\n",
    "test_text = vectorizer.transform(Xtest['employer_name'] + ' ' + Xtest['key_skills_name'] + ' ' + Xtest['professional_roles_name'] + ' ' + Xtest['languages_name'] + ' ' + Xtest['lemmaized_wo_stopwords_raw_description'] + ' ' + Xtest['lemmaized_wo_stopwords_raw_branded_description'] + \" \" + Xtest['name_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c292a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# слияние\n",
    "from scipy.sparse import hstack\n",
    "stacked_data = hstack([train_text, X_train_categ])\n",
    "stacked_data_test = hstack([test_text, X_test_categ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02479beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37285.10826209732"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# первый способ\n",
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=0.9, random_state=241)\n",
    "clf.fit(stacked_data, X['salary_mean_net'])\n",
    "predict = clf.predict(stacked_data_test)\n",
    "pd.DataFrame({'id': Xtest['id'], 'salary_mean_net': predict}).to_csv('aaa.tsv', sep=\"\\t\", index=False)\n",
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33830f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перебор параметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Определение параметров и их значений для перебора\n",
    "param_grid = {\n",
    "    'alpha': [0.6, 0.7, 0.8],\n",
    "    'random_state': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Создание модели и настройка с использованием решетчатого поиска\n",
    "rf_model = Ridge()\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3)\n",
    "grid_search.fit(stacked_data, X['salary_mean_net'])\n",
    "\n",
    "# Вывод наилучших гиперпараметров и оценки\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b38fc8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34255.28169912661"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor(max_depth=15, random_state=20)\n",
    "clf.fit(stacked_data, X['salary_mean_net'])\n",
    "predict = clf.predict(stacked_data_test)\n",
    "pd.DataFrame({'id': Xtest['id'], 'salary_mean_net': predict}).to_csv('aaa.tsv', sep=\"\\t\", index=False)\n",
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5723abc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 15, 'random_state': 20}\n",
      "Best Cross-Validation Score: 0.3890850463623037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Определение параметров и их значений для перебора\n",
    "param_grid = {\n",
    "    'max_depth': [15],\n",
    "    'random_state': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Создание модели и настройка с использованием решетчатого поиска\n",
    "rf_model = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=3)\n",
    "grid_search.fit(stacked_data, X['salary_mean_net'])\n",
    "\n",
    "# Вывод наилучших гиперпараметров и оценки\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f5e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
